---
title: "**Classical Statistical Inference Exercises**"
author: "*Lucas Romero Fern√°ndez*"
date: "*December 2024*"
output:
  html_document: default
  pdf_document:
    latex_engine: xelatex
fontsize: 10pt
---

```{r, echo = F}
#install.packages("formatR")
library(formatR)
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 70), tidy = TRUE)
```

# Exercise 1

**A computer auditor wants to investigate the proportion of routines in a program that present a certain irregularity. For this, she observes 100 routines, resulting in that 20 of them present some irregularity.**

**a) With these data, look for confidence limits for the proportion $p$ of routines of the population that present this irregularity with a probability of 95%.**

**b) Which is the minimum number of samples such that the width of the interval is less than 5%?**

**a)**

```{r}
# Variables of the exercise

Irr_routines = 20 # Num. of routines that present some irregularity.

Tot_routines = 100 # Total num. of routines observed.

Conf_level = 0.95 # Wanted probability of presenting this irregularity, in this case, 95%.

p = Irr_routines/Tot_routines # Proportion of routines that present some irregularity.

cat("p =", p)
```

Assuming a normal population, the confidence limits (or equivalently, the confidence interval), given these data, can be obtained using the **prop.test** function in the **R** programming language, keeping in mind to explicitly designate in the function the argument *correct = FALSE* (Yates' continuity correction disabled) to make sure that the expressions used are identical to the ones seen frequently:

```{r}
prop.test(Irr_routines, Tot_routines, conf.level = Conf_level, correct = FALSE)
```

As can be seen, the confidence interval of $95$% for the proportion $p$ of irregular routines in a program for this population is $ICp = (0.1333669, 0.2888292)$ ($\sim 13.3$% - $28.9$%).

**b)**

Assuming that the proportion $p$ maintains the same value of section **a)** ($p\equiv \hat{p}$) and that the probability is still of $95$% (which means $\alpha = 1-0.95 = 0.05$), the minimum number of samples $n_{min}$ such that the width of the confidence interval is less than $5$% can be calculated employing the definition of confidence interval (knowing the proportion), which results in these expressions: 
\begin{equation}
    z_{0.025}\sqrt{\frac{\hat{p}(1 - \hat{p})}{n}} \leq \frac{0.05}{2} \rightarrow n \geq 1600\hat{p}(1 - \hat{p})z_{0.025}^2 = n_{min} \in \mathbb{Z}.
\end{equation}

Finally, $z_{0.025}$ can be computed with **R** and, with its value and the value of $\hat{p}$, $n_{min}$ can be obtained:

```{r}
z0025 = qnorm(0.025)

nmin = ceiling(1600 * p * (1 - p) * z0025^2) # To choose the nearest superior integer.

cat("nmin =",nmin)
```

Hence, the minimum number of routines such that the width of the confidence interval is less than $5$% is $984$ total routines.

# Exercise 2

**A driving school claims that 70% of its students pass the driving test the first time they try. To verify this statement, 250 students from the driving school and 160 of them have approved the first time. Perform a hypothesis test to evaluate the claim of driving school with a significance level of 5%.**

```{r}
# Variables of the exercise

p = 0.7 # Claimed prop. of students to pass the driving test on their first try (70%).

# Both populations

Stud_1_try = 160 # Num. of students that passed the driving test (1st try).

Tot_stud = 250 # Total num. of students.

Sign_level = 0.05 # Significance level (equivalent to alpha) (5%).
```

As the objective of this exercise is to determine if the claims of the driving school are true or not, it is rational to consider a bilateral hypothesis test, in other words, choosing the null hypothesis $H_{0}$ as the statement being true and the alternative hypothesis $H_{1}$ as the statement being false. Representing this hypothesis test symbolically:
$$H_{0}: p = 0.7,$$
$$H_{1}: p \neq 0.7.$$

Assuming again a normal population, this hypothesis test can be performed with the same **R** function as in the previous exercise (in the bilateral hypothesis test case):

```{r}
prop.test(Stud_1_try, Tot_stud, p = p, conf.level = 1 - Sign_level, correct = FALSE)
```

As shown in the results, the p-value is slightly smaller than the significance level $\alpha$ (p-value $= 0.03843 < 0.05 = \alpha$), which, in the basis of the technique of hypothesis testing, concludes that the null hypothesis $H_{0}$ has to be rejected in favor of the alternative hypothesis $H_{1}$, which implies that there is enough reason to think that the aforementioned statement is false with this significance level.

For further study, a unilateral (on the left) hypothesis test can be considered, that can be represented symbolically:
$$H_{0}: p = 0.7,$$
$$H_{1}: p < 0.7.$$
Assuming again a normal population, this hypothesis test can be performed with the same **R** function as previously done in the exercise with a new argument *alternative = "less"*, which chooses the case of unilateral (on the left) hypothesis test:

```{r}
prop.test(Stud_1_try, Tot_stud, p = p, alternative = "less", conf.level = 1 - Sign_level, correct = FALSE)
```

As seen in the results, the p-value in this new test is considerably smaller than the significance level $\alpha$ (p-value $= 0.01922 < 0.05 = \alpha$), which concludes that the null hypothesis $H_{0}$ has to be rejected again in favor of the alternative hypothesis $H_{1}$, which implies that the claimed statement is false with this significance level.

# Exercise 3

**We have 10 computers and we want to optimize their operation. To this end the amount of RAM memory has been increased. A performance test (measured in seconds) is passed before and after this change. The results were: **

|   Execution time   |       |        |        |        | Computer |        |        |      |        |        |
|:------------------:|:-----:|:------:|:------:|:------:|:--------:|:------:|:------:|:----:|:------:|:------:|
|                    |   1   |    2   |    3   |    4   |     5    |    6   |    7   |   8  |    9   |   10   |
|       Before       | 98.70 | 100.48 | 103.75 | 114.41 |   97.82  |  91.13 |  85.42 | 96.8 | 107.76 | 112.94 |
|        After       | 99.51 | 113.44 | 108.74 |  97.92 |  103.54  | 104.75 | 109.69 | 90.8 | 110.04 | 110.09 |

**Assuming a normal distribution of the execution times, evaluate the statistical significance of the change.**

```{r}
# Variables of the exercise

Exec_time_before = c(98.70, 100.48, 103.75, 114.41, 97.82, 91.13, 85.42, 96.8, 107.76, 112.94) # Execution times before optimization.

Exec_time_after = c(99.51, 113.44, 108.74, 97.92, 103.54, 104.75, 109.69, 90.8, 110.04, 110.09) # Execution times after optimization.

Tot_computers = 10 # Total num. of computers.

Conf_level = 0.95 # Confidence level, which if unspecified, is 95%.

Sign_level = 0.05 # Significance level (equivalent to alpha) (equal to 1 - Conf_level).

mean_before = mean(Exec_time_before) # Mean of execution times before optimization [s].

mean_after = mean(Exec_time_after) # Mean of execution times after optimization [s].

cat("mean_before =", mean_before)

cat("mean_after =", mean_after)

cat("mean_difference =", mean_after - mean_before) # Difference between both means [s].
```

As the aim of this exercise is to determine if there is statistical significance in the change, it is logical to consider a bilateral hypothesis test, in other words, choosing the null hypothesis $H_{0}$ as the mean difference being equal to zero and the alternative hypothesis $H_{1}$ as the mean difference not being equal to zero. Representing this hypothesis test symbolically:
$$H_{0}: \mu_{diff} = 0,$$
$$H_{1}: \mu_{diff} \neq 0.$$

Since this type of hypothesis test with means depends on whether the variances are equal or not for both populations, it is necessary to, first, perform a bilateral hypothesis test on the variances of the form of:
$$H_{0}: \sigma_{before}^2 = \sigma_{after}^2,$$
$$H_{1}: \sigma_{before}^2 \neq \sigma_{before}^2,$$
which, assuming a normal distribution of the execution times, can be done using the **R** function **var.test** in the library *EnvStats*, with the same considerations as **prop.test** in previous exercises:

```{r}
library(EnvStats)

var.test(Exec_time_before, Exec_time_after, conf.level = Conf_level, correct = FALSE)
```

Since these results show that the p-value is considerably greater than the significance level $\alpha$ (p-value $= 0.4448 > 0.05 = \alpha$), the alternative hypothesis can be neglected and, therefore, both variances can be considered equal with this significance level.

With the same assumptions as before and that the execution times are interpreted as paired data (dependent of each other) between populations, this hypothesis test between two populations can be performed with the **R** function **t.test**, with the same considerations as **var.test** in previous exercises, except the arguments *paired = TRUE*, which indicates that the data is paired between populations, and *var.equal = TRUE*, which implies that the variances of the two populations are equal:

```{r}
t.test(Exec_time_before, Exec_time_after, paired = TRUE, var.equal = TRUE, conf.level = Conf_level, correct = FALSE)
```

Since the p-value shown in the results is significantly greater than the significance level $\alpha$ (p-value $= 0.3034 > 0.05 = \alpha$), $H_{0}$ has to be accepted in favor of $H_{1}$, which implies that there is no statistical significance in the change done for the optimization with this significance level.

# Exercise 4

**A sample of 40 bulbs of brand A gave a half life of 2280 hours, with a standard deviation of 84 hours. Another sample of 35 bulbs of brand B gave a half-life of 2320 hours with a standard deviation of 100 hours. Can it be stated, at the 0.01 level, that the half-life for brand B is longer? Assume that the life times of the bulbs follow normal distributions.**

```{r}
# Variables of the exercise

half_life_A = 2280 # Mean of the half life of the bulbs in the sample of brand A [hours].

stand_dev_A = 84 # Stand. deviation of the bulbs in the sample of brand A [hours].

half_life_B = 2320 # Mean of the half life of the bulbs in the sample of brand B [hours].

stand_dev_B = 100 # Stand. deviation of the bulbs in the sample of brand B [hours].

Tot_bulbs_A = 40 # Total num. of bulbs in the sample of brand A.

Tot_bulbs_B = 32 # Total num. of bulbs in the sample of brand B.

Sign_level = 0.01 # Significance level (equivalent to alpha) (equal to 1 - Conf_level).

Conf_level = 0.99 # Confidence level (equal to 1 - Sign_level).

# With these values and assuming normal distributions, raw data can be simulated:

Sample_A = c(half_life_A + stand_dev_A * scale(rnorm(Tot_bulbs_A))) # Brand A.

Sample_B = c(half_life_B + stand_dev_B * scale(rnorm(Tot_bulbs_B))) # Brand B.
```

As the goal of this exercise is to determine if the half life of the bulbs for brand B can be considered longer than for brand A ($\mu_{A} < \mu_{B}$), it is reasonable to, once again, consider a unilateral (on the left) hypothesis test, in other words, choosing the null hypothesis $H_{0}$ as the mean of brand A ($\mu_{A}$) and the mean of brand B ($\mu_{B}$) being equal and the alternative hypothesis $H_{1}$ as the mean of brand A being smaller than the mean of brand B. Representing this hypothesis test symbolically:
$$H_{0}: \mu_{A} = \mu_{B},$$
$$H_{1}: \mu_{A} < \mu_{B}.$$

Since this type of hypothesis test with means depends on whether the variances are equal or not for both populations, like in the previous exercise, it is convenient to, first, perform a bilateral hypothesis test on the variances of the form of:
$$H_{0}: \sigma_{A}^2 = \sigma_{B}^2,$$
$$H_{1}: \sigma_{A}^2 \neq \sigma_{B}^2,$$

which, assuming a normal distribution of the life times, can be done using the **R** function **var.test** already used in the previous exercise:

```{r}
var.test(Sample_A, Sample_B, conf.level = Conf_level, correct = FALSE)
```

Since, in these results, the p-value shown is considerably greater than the significance level $\alpha$ (p-value $= 0.3008 > 0.01 = \alpha$), the alternative hypothesis can be neglected and, for that reason, both variances can be considered equal with this significance level.

With the same assumptions as before and that the life times are interpreted as unpaired data (not dependent of each other) between the two brands, this hypothesis test between two populations can be performed with the **R** function **t.test** as already seen in the previous exercise:

```{r}
t.test(Sample_A, Sample_B, alternative = "less", paired = FALSE, var.equal = TRUE, conf.level = Conf_level, correct = FALSE)
```

As the p-value shown in the results is slightly greater than the significance level $\alpha$ (p-value $= 0.03466 > 0.01 = \alpha$), $H_{0}$ has to be accepted in favor of $H_{1}$, which indicates that there is not enough proof to state that the half-life for brand B is longer than for brand A with this significance level.

# Exercise 5

**The number of weekly failures of a server is observed during 100 weeks, obtaining the following values: **

| Number of weekly failures |  0 |  1 |  2 |  3 | 4 | 5 or more |
|:-------------------------:|:--:|:--:|:--:|:--:|:-:|:---------:|
|      Number of weeks      | 10 | 24 | 32 | 23 | 6 |     5     |

**The average number of failures per week was 2.1. Test the hypothesis that the number of weekly failures follows a Poisson law.**

```{r}
# Variables of the exercise

Obs_values = c(10, 24, 32, 23, 6, 5) # Observed absolute frequencies of num. of weeks.

Tot_weeks = 100 # Total num. of weeks in which weekly failures were observed.

lambda = 2.1 # Average/Mean num. of failures per week.

Conf_level = 0.95 # Confidence level, which if unspecified, is 95%.

Sign_level = 0.05 # Significance level (equivalent to alpha) (equal to 1 - Conf_level).
```

Given that the objective of this exercise is to test if the number of weekly failures ($X$) follows a Poisson law, it is convenient to consider a goodness-of-fit hypothesis test, in other words, choosing the null hypothesis $H_{0}$ as $X$ follows a Poisson law and the alternative hypothesis $H_{1}$ as the opposite ($X$ does not follow a Poisson law). Representing this hypothesis test symbolically:
$$H_{0}: X\ follows\ a\ Poisson\ law,$$
$$H_{1}: X\ does\ not\ follow\ a\ Poisson\ law.$$

For this reasoning, $X \backsim P_{0}(\lambda = 2.1)$ and, because of this, the expected values (or expected absolute frequencies) of the number of weeks in which a specific number of weekly failures occurred can be calculated using the observed ones in this manner:

```{r}
Poisson_probs = c(dpois(0, lambda), dpois(1, lambda), dpois(2, lambda), dpois(3, lambda), dpois(4, lambda), 1 - ppois(4, lambda))
# Last element in the previous vector corresponds to the prob. in the region of "5 or more" weekly failures.

Expec_values = Tot_weeks * Poisson_probs

cat("Expec_values =", Expec_values)
```

Since all the expected values meet the conditions of the test (expected values $\geq 5$) and the data is of discrete nature, a $\chi^2$ test can be performed using the **R** function **chisq.test**:

```{r}
chisq.test(Obs_values, p = Poisson_probs)
```

Following the technique of prior hypothesis testing, since the p-value seen in the results is considerably greater than the significance level $\alpha$ (p-value $= 0.5311 > 0.05 = \alpha$), $H_{0}$ has to be accepted in favor of $H_{1}$, which signifies that the number of weekly failures follows a Poisson law with this significance level.

# Exercise 6

**The following contingency table lists, for 120 people, the number of books they read in the past year and the number of spelling mistakes made on a literature test (the values in the table indicate absolute frequencies).**

| Mistakes $\setminus$ Books | < 2 | [2, 5) | [5, 10) | $\geq$ 10 |
|:--------------------------:|:---:|:------:|:-------:|:---------:|
|             < 3            |  2  |    7   |    17   |     30    |
|           [3, 10)          |  10 |    7   |    8    |     3     |
|          $\geq$ 10         |  21 |   12   |    3    |     0     |

**Can we conclude that there is a statistical dependence between the number of mistakes and the number of books read?**

```{r}
# Variables of the exercise

Obs_values = as.table(matrix(c(2, 10, 21, 7, 7, 12, 17, 8, 3, 30, 3, 0), nrow = 3, ncol = 4, byrow = FALSE))
# Observed absolute frequencies of mistakes and books (in matrix form).

Tot_people = 120 # Total num. of people present in this literature test.

Conf_level = 0.95 # Confidence level, which if unspecified, is 95%.

Sign_level = 0.05 # Significance level (equivalent to alpha) (equal to 1 - Conf_level).
```

Given that the aim of this exercise is to determine if there is a statistical dependency between the number of mistakes and the number of books read, it is reasonable to consider an independence hypothesis test, in other words, choosing the null hypothesis $H_{0}$ as the number of mistakes and the number of books read are independent of each other (independent variables) and the alternative hypothesis $H_{1}$ as the number of mistakes and the number of books read are not independent of each other (dependent variables). Representing this hypothesis test symbolically:
$$H_{0}: The\ variables\ are\ independent,$$
$$H_{1}: The\ variables\ are\ dependent.$$
As in the previous exercise, a $\chi^2$ test can be performed using the **R** function **chisq.test**, in this case, only needing to use the table elements:

```{r}
chisq.test(Obs_values)
```

Following the basis of prior hypothesis testing, since the p-value shown in the results is significantly smaller than the significance level $\alpha$ (p-value $= 2.866^{-11} < 0.05 = \alpha$), $H_{0}$ has to be rejected in favor of $H_{1}$, which entails that the number of mistakes and the number of books read are variables dependent on each other with this significance level.
